# üìä An√°lisis de Sentimientos y Clasificaci√≥n de Rese√±as de Productos Tecnol√≥gicos

Este proyecto aplica t√©cnicas de Procesamiento de Lenguaje Natural (NLP) y Deep Learning para analizar m√°s de 3000 rese√±as en espa√±ol de productos tecnol√≥gicos como smartphones, laptops y dispositivos de audio. El objetivo es predecir la puntuaci√≥n de una rese√±a bas√°ndose √∫nicamente en su contenido textual.

## üß† Objetivos

- Preprocesar texto en espa√±ol aplicando:
  - Tokenizaci√≥n
  - Lematizaci√≥n
  - POS-tagging
  - Reconocimiento de Entidades Nombradas (NER)
- Evaluar el sentimiento utilizando polaridad y subjetividad
- Vectorizar texto con TF-IDF
- Entrenar una red neuronal para predecir la puntuaci√≥n de las rese√±as

## üìÅ Dataset

El conjunto de datos consiste en un archivo Excel con m√°s de 3000 rese√±as en espa√±ol sobre productos tecnol√≥gicos. Cada rese√±a incluye:

- Texto libre con la opini√≥n del usuario
- Puntuaci√≥n (de 1 a 5 estrellas)

## üîß Herramientas y Librer√≠as Utilizadas

- **Python**: lenguaje de programaci√≥n principal
- **Pandas**: manipulaci√≥n de datos
- **SpaCy** (`es_core_news_sm`): an√°lisis ling√º√≠stico (lemmatizaci√≥n, POS, NER)
- **NLTK**: apoyo en procesamiento de texto
- **TextBlob**: an√°lisis de sentimientos
- **Scikit-learn**: TF-IDF y preparaci√≥n de datos
- **Keras + TensorFlow**: modelado con redes neuronales

## üîç Flujo del Proyecto

### 1. An√°lisis Exploratorio del Texto

Las rese√±as contienen opiniones informales y subjetivas, lo que representa un reto interesante para aplicar NLP. Se analizaron caracter√≠sticas como longitud, distribuci√≥n de puntuaciones y ejemplos de textos.

### 2. Preprocesamiento del Lenguaje Natural

Se aplicaron t√©cnicas clave para preparar el corpus:

- **Tokenizaci√≥n** y **lematizaci√≥n**
- **Eliminaci√≥n de stopwords**
- **POS tagging**
- **NER (Reconocimiento de Entidades Nombradas)**

Esto permiti√≥ normalizar y limpiar los textos, prepar√°ndolos para el an√°lisis.

### 3. An√°lisis de Sentimientos

Utilizando TextBlob se extrajeron dos m√©tricas:

- **Polaridad** (de -1 a 1): grado de negatividad o positividad
- **Subjetividad** (de 0 a 1): carga emocional del texto

### 4. Vectorizaci√≥n TF-IDF

Se aplic√≥ **TF-IDF** para transformar el texto en vectores num√©ricos, destacando t√©rminos relevantes y minimizando palabras frecuentes con poco valor predictivo.

### 5. Modelado con Redes Neuronales

Se construyeron dos modelos con Keras:

#### üîπ Modelo de Regresi√≥n
- Predice la puntuaci√≥n como valor continuo
- Activaci√≥n lineal en la capa de salida

#### üîπ Modelo de Clasificaci√≥n Multiclase
- Salida con funci√≥n `softmax`
- Clasifica directamente la puntuaci√≥n entre 1 y 5

Ambos modelos mostraron buenos resultados. El modelo de clasificaci√≥n obtuvo una **alta precisi√≥n** y bajo error, mostrando una fuerte correlaci√≥n entre predicciones y valores reales.

---

## ‚úÖ Conclusiones

El proyecto demostr√≥ que es posible procesar texto en espa√±ol de forma efectiva y predecir la puntuaci√≥n de una rese√±a con modelos de NLP y Deep Learning. Se logr√≥:

- Capturar patrones en el lenguaje natural
- Transformar texto en representaciones num√©ricas √∫tiles
- Predecir el "sentimiento" cuantificable de una rese√±a

## üöÄ Aplicaciones Potenciales

- Sistemas de recomendaci√≥n
- Evaluaci√≥n autom√°tica de rese√±as
- An√°lisis de reputaci√≥n de productos
- Feedback automatizado de clientes

## üìå Posibles Mejoras Futuras

- Incluir **embeddings preentrenados** 
- Entrenar modelos propios de **an√°lisis de sentimientos**
- Probar **modelos m√°s complejos** 
- Aplicar **t√©cnicas de regularizaci√≥n** para evitar overfitting

---

## üìÇ Acceso al proyecto

üîó [Drive con notebook y archivos](https://drive.google.com/drive/folders/1QFKoEDvgIjWeuYxfbJSS4OmLI4iLB_an)


